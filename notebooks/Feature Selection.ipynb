{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skfeature.function.information_theoretical_based import CMIM\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "%run ../predict_voting_outcomes/data_preparation.py\n",
    "%run ../predict_voting_outcomes/feature_preprocessing.py\n",
    "%run ../predict_voting_outcomes/cross_validation_setup.py\n",
    "\n",
    "np.random.seed(2016) # set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data from disk\n",
    "data = pd.read_csv('../data/imputed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill missing values\n",
    "data = fill_missing_values(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# encode labels\n",
    "data = encode_cat_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# consider only this feature age mapping and see if it is of any importance\n",
    "features = data.columns.drop('Party')\n",
    "mask = (data.Party.notnull())\n",
    "\n",
    "X = data.loc[mask, features]\n",
    "y = (data[mask].Party == 'Democrat').astype(int)\n",
    "\n",
    "Xtest = data.loc[~mask, features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Only include discrete variables for now **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X     = X.select_dtypes(include=['int64'])\n",
    "Xtest = Xtest.select_dtypes(include=['int64'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Split into training and test splits **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtr, Xte, ytr, yte = split_dataset(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Feature Selection **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_indices = CMIM.cmim(Xtr.values, ytr.values, n_selected_features=25)\n",
    "selected_features = X.columns[feature_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Cross-validation **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cv score: 0.620119 and std: 0.010071\n"
     ]
    }
   ],
   "source": [
    "est = RandomForestClassifier(n_estimators=1000, max_depth=5, max_features='sqrt', random_state=12313)\n",
    "cv_scores = perform_cross_validation(Xtr, ytr, est)\n",
    "print('Mean cv score: %f and std: %f'%(cv_scores.mean(), cv_scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on held out set: 0.612208\n"
     ]
    }
   ],
   "source": [
    "# score on unseen examples 0.612208\n",
    "est.fit(Xtr, ytr)\n",
    "yhat = est.predict(Xte)\n",
    "print('Accuracy on held out set: %f'%(accuracy_score(yte, yhat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** XGBClassifier **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(max_depth=3, learning_rate=0.09, gamma=2, min_child_weight=1, \\\n",
    "                          n_estimators=1000, colsample_bytree=0.6, subsample=0.9, seed=1231)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.36 s, sys: 36 ms, total: 2.4 s\n",
      "Wall time: 670 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.6,\n",
       "       gamma=2, learning_rate=0.09, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=1000, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=1231, silent=True, subsample=0.9)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "model.fit(\n",
    "    Xtr.values, \n",
    "    ytr.values, \n",
    "    eval_set = [(Xte.values, yte.values)], \n",
    "    early_stopping_rounds = 50,\n",
    "    verbose = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63195691202872528"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = model.predict(Xte.values)\n",
    "score = accuracy_score(yte, p)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132.22222222222223"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_iteration / 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Bagging Different Classifiers **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BaggingClassifier:\n",
    "    \n",
    "    @staticmethod\n",
    "    def majority_vote(preds):\n",
    "        \"\"\"\n",
    "        Given an array of predictions from various classifiers\n",
    "        return single array with ensemble of predictions based on\n",
    "        simple majority voting\n",
    "\n",
    "        Input: list of list [[y1, y2, y3, ..], [y1, y2, y3, ...], ..] \n",
    "        Output: final prediction [y1, y2, y3, ..]\n",
    "        \"\"\"\n",
    "        length = [len(pred) for pred in preds]\n",
    "\n",
    "        if len(set(length)) != 1:\n",
    "            raise ValueError('Predictions must be of the same length')\n",
    "\n",
    "        pred_matrix = np.matrix(preds)\n",
    "        ensemble_preds = []\n",
    "\n",
    "        for i in range(len(preds[0])):\n",
    "            pred_column = np.array(pred_matrix[:, i]).ravel()\n",
    "            common_pred = Counter(pred_column)\n",
    "            most_common = common_pred.most_common()[0][0]\n",
    "\n",
    "            ensemble_preds.append(most_common)\n",
    "\n",
    "        return ensemble_preds\n",
    "    \n",
    "    def __init__(self, estimators, voting='hard'):\n",
    "        \"\"\"\n",
    "        Estimators will be a list of tuples of (n_selected_features, estimator)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.estimators = estimators\n",
    "        self.fitted_models = []\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "#         for n_selected_features, model in self.estimators:\n",
    "#             feature_indices = CMIM.cmim(X.values, y.values, n_selected_features=n_selected_features)\n",
    "#             selected_features = X.columns[feature_indices]\n",
    "#             model.fit(X[selected_features], y)    \n",
    "#             self.fitted_models.append((selected_features, model))\n",
    "        \n",
    "        for model in self.estimators:\n",
    "            model.fit(X, y)\n",
    "            self.fitted_models.append(model)\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        \n",
    "#         for selected_features, model in self.fitted_models:\n",
    "#             yhat = model.predict(X[selected_features])\n",
    "#             preds.append(yhat)\n",
    "        \n",
    "        for model in self.fitted_models:\n",
    "            yhat = model.predict(X)\n",
    "            preds.append(yhat)\n",
    "        \n",
    "        final_preds = self.majority_vote(preds)\n",
    "        return final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pipe1 = (15, xgb.XGBClassifier(max_depth=3, learning_rate=0.08, min_child_weight=1, \\\n",
    "#                           n_estimators=150, colsample_bytree=0.8, subsample=0.8, seed=231))\n",
    "# pipe2 = (15, xgb.XGBClassifier(max_depth=4, learning_rate=0.08, min_child_weight=1, \\\n",
    "#                           n_estimators=120, colsample_bytree=0.8, subsample=0.8, seed=1231))\n",
    "# pipe3 = (25, xgb.XGBClassifier(max_depth=3, learning_rate=0.08, min_child_weight=1, \\\n",
    "#                           n_estimators=53, colsample_bytree=0.8, subsample=0.8, seed=2231))\n",
    "# pipe4 = (25, xgb.XGBClassifier(max_depth=4, learning_rate=0.08, min_child_weight=1, \\\n",
    "#                           n_estimators=78, colsample_bytree=0.8, subsample=0.8, seed=233331))\n",
    "\n",
    "# 226.66666666666666\n",
    "\n",
    "estimators = [xgb.XGBClassifier(max_depth=3, learning_rate=0.09, gamma=2, min_child_weight=1, \\\n",
    "                          n_estimators=1000, colsample_bytree=0.6, subsample=0.9, seed=np.random.randint(0, 1000)) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.BaggingClassifier at 0x7fe76a1baa90>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag = BaggingClassifier(estimators)\n",
    "bag.fit(Xtr, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the held out set:0.625673 \n"
     ]
    }
   ],
   "source": [
    "yhat = bag.predict(Xte)\n",
    "print('Accuracy on the held out set:%f '%(accuracy_score(yte, yhat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Full Training **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag = BaggingClassifier(estimators)\n",
    "bag.fit(X, y)\n",
    "predictions = bag.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est.fit(X[selected_features], y)\n",
    "predictions = est.predict(Xtest[selected_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../data/sampleSubmission2016.csv')\n",
    "prediction_labels = map(lambda x: 'Democrat' if x == 1 else 'Republican', predictions)\n",
    "sub['Predictions'] = list(prediction_labels)\n",
    "timestamp = str(datetime.now()).replace(' ', '_')\n",
    "sub.to_csv('../submissions/bag_10_xgbs_without_cmim%s.csv'%(timestamp), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
